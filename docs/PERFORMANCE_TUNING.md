# Performance Tuning Guide - Smart Motion Detector v2

Bu dokÃ¼man, test sÃ¼recini hÄ±zlandÄ±rmak iÃ§in **kanÄ±tlanmÄ±ÅŸ ayarlar** ve **best practices** iÃ§erir.

**Kaynak**: 2024-2025 araÅŸtÄ±rma makaleleri ve production deployments

---

## ğŸ¯ HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Ã–nerilen Ayarlar)

### YOLOv8 Model SeÃ§imi

| Model | KullanÄ±m Senaryosu | FPS (T4 GPU) | mAP | Parametre |
|-------|-------------------|--------------|-----|-----------|
| **yolov8n-person** | Edge devices, Raspberry Pi, Ã§ok kamera | ~680 FPS | 37.3 | 3.2M |
| **yolov8s-person** | Server, yÃ¼ksek doÄŸruluk gerekli | ~375 FPS | 44.9 | 11.2M |

**Ã–neri**: 
- **1-4 kamera**: `yolov8s-person` (daha yÃ¼ksek doÄŸruluk)
- **5+ kamera veya edge device**: `yolov8n-person` (daha hÄ±zlÄ±)

---

## ğŸŒ¡ï¸ Thermal Camera AyarlarÄ±

### 1. Thermal Sensitivity (NETD)

**Kritik Metrik**: KameranÄ±n algÄ±layabileceÄŸi en kÃ¼Ã§Ã¼k sÄ±caklÄ±k farkÄ±

| NETD DeÄŸeri | Kalite | Ã–nerilen KullanÄ±m |
|-------------|--------|-------------------|
| <25mK | MÃ¼kemmel | Professional surveillance |
| <50mK | Ä°yi | Genel gÃ¼venlik |
| <60mK | Kabul Edilebilir | Budget projeler |

**Ã–neri**: Minimum **<50mK** NETD deÄŸerine sahip kamera kullanÄ±n.

---

### 2. Resolution ve Frame Rate

**Ã–nerilen Ayarlar**:
```python
# Thermal Camera
THERMAL_RESOLUTION = (320, 240)  # Minimum
THERMAL_RESOLUTION_OPTIMAL = (640, 480)  # Ã–nerilen
THERMAL_FPS = 25  # Hz (minimum)
```

**Neden?**
- 320x240: Temel detection iÃ§in yeterli
- 640x480: Person identification iÃ§in ideal
- 25 Hz: Hareket eden kiÅŸileri yakalamak iÃ§in minimum

---

### 3. Temperature Range

```python
# Person Detection
TEMP_RANGE_MIN = 30  # Â°C
TEMP_RANGE_MAX = 40  # Â°C

# GeniÅŸ Ã‡evre (opsiyonel)
TEMP_RANGE_WIDE_MIN = -20  # Â°C
TEMP_RANGE_WIDE_MAX = 120  # Â°C
```

**Not**: Ä°nsan vÃ¼cut sÄ±caklÄ±ÄŸÄ± 30-40Â°C arasÄ±, ama Ã§evre faktÃ¶rleri iÃ§in geniÅŸ range kullanÄ±labilir.

---

### 4. Image Pre-processing (Thermal iÃ§in Kritik!)

**Problem**: Thermal gÃ¶rÃ¼ntÃ¼ler dÃ¼ÅŸÃ¼k kontrast ve gÃ¼rÃ¼ltÃ¼lÃ¼ olabilir.

**Ã‡Ã¶zÃ¼m**: Histogram enhancement

```python
import cv2
import numpy as np

def enhance_thermal_image(thermal_frame):
    """
    Kurtosis-based histogram enhancement
    Kaynak: Springer 2025 research
    """
    # CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(thermal_frame)
    
    # Gaussian blur (noise reduction)
    enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)
    
    return enhanced
```

**Performans Ä°yileÅŸtirmesi**: mAP 0.93 â†’ 0.99 (OSU thermal dataset)

---

## ğŸ¥ RTSP Stream AyarlarÄ±

### 1. Resolution ve FPS

**Kamera Stream**:
```python
# Kameradan gelen stream
CAMERA_STREAM_RESOLUTION = (1280, 720)  # veya (1920, 1080)
CAMERA_STREAM_FPS = 25  # veya 30
```

**Inference iÃ§in Downscale**:
```python
# YOLOv8'e gÃ¶nderilen frame
INFERENCE_RESOLUTION = (640, 640)  # veya (640, 480)
INFERENCE_FPS = 5  # Her frame'i iÅŸlemeye gerek yok!
```

**Neden Downscale?**
- 1080p â†’ 640x640: ~9x daha hÄ±zlÄ± inference
- 5 FPS inference: Person detection iÃ§in yeterli (sÃ¼rekli hareket deÄŸil)

---

### 2. RTSP Protocol AyarlarÄ±

**OpenCV VideoCapture AyarlarÄ±**:
```python
import cv2

# TCP kullan (UDP yerine) - frame tearing Ã¶nler
rtsp_url = "rtsp://user:pass@192.168.1.100:554/stream?tcp"

cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)

# Buffer size ayarla (latency azaltÄ±r)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

# Codec ayarla
cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))
```

**Kritik**: `?tcp` parametresi ekleyin! UDP packet loss'tan kaynaklanan artifact'larÄ± Ã¶nler.

---

### 3. MJPEG vs WebRTC

| Ã–zellik | MJPEG | WebRTC |
|---------|-------|--------|
| **Latency** | 1-3 saniye | <500ms |
| **Browser Support** | âœ… Native | âœ… Native (modern browsers) |
| **Bandwidth** | YÃ¼ksek | DÃ¼ÅŸÃ¼k (H.264/H.265) |
| **Complexity** | Basit | Orta (STUN/TURN gerekli) |
| **Encryption** | Opsiyonel | âœ… Zorunlu (SRTP/DTLS) |

**Ã–neri**:
- **MVP iÃ§in**: MJPEG (kolay implement)
- **Production iÃ§in**: WebRTC (dÃ¼ÅŸÃ¼k latency + gÃ¼venlik)

**Hybrid YaklaÅŸÄ±m** (En Ä°yi):
```
Camera â†’ RTSP (H.264) â†’ Backend â†’ WebRTC (browser)
                       â†’ MJPEG (fallback)
```

---

## ğŸ¤– YOLOv8 Detection AyarlarÄ±

### 1. Confidence Threshold

**Thermal Camera iÃ§in Ã–nerilen**:
```python
# Standart ayar
CONFIDENCE_THRESHOLD = 0.25  # Default

# Thermal iÃ§in optimize
CONFIDENCE_THERMAL_CLEAR = 0.4  # Ä°yi hava koÅŸullarÄ±
CONFIDENCE_THERMAL_CHALLENGING = 0.2  # YaÄŸmur, sis, kar

# Color camera iÃ§in
CONFIDENCE_COLOR = 0.5  # Daha yÃ¼ksek threshold
```

**Neden FarklÄ±?**
- Thermal: DÃ¼ÅŸÃ¼k kontrast â†’ daha dÃ¼ÅŸÃ¼k threshold
- Color: YÃ¼ksek detay â†’ daha yÃ¼ksek threshold (false positive azaltÄ±r)

---

### 2. NMS (Non-Maximum Suppression)

```python
NMS_IOU_THRESHOLD = 0.45  # Default (genelde deÄŸiÅŸtirmeye gerek yok)
```

---

### 3. Inference Optimization

**TensorRT (NVIDIA GPU)**:
```python
from ultralytics import YOLO

# Model export
model = YOLO('yolov8n-person.pt')
model.export(format='engine')  # TensorRT

# Inference
model = YOLO('yolov8n-person.engine')
results = model(frame)
```

**Performans**: 2-3x daha hÄ±zlÄ±!

**ONNX (CPU/Cross-platform)**:
```python
model.export(format='onnx')
model = YOLO('yolov8n-person.onnx')
```

---

## ğŸ­ Zone/ROI AyarlarÄ±

### 1. Polygon Validation

```python
MIN_POLYGON_POINTS = 3
MAX_POLYGON_POINTS = 20
```

### 2. Motion Sensitivity

**Thermal Camera iÃ§in**:
```python
MOTION_SENSITIVITY_THERMAL = 8  # (1-10 scale)
MOTION_MIN_AREA_THERMAL = 450  # pixels
MOTION_COOLDOWN_THERMAL = 4  # seconds
```

**Color Camera iÃ§in**:
```python
MOTION_SENSITIVITY_COLOR = 7
MOTION_MIN_AREA_COLOR = 500  # pixels
MOTION_COOLDOWN_COLOR = 5  # seconds
```

**Kaynak**: API_CONTRACT.md presets

---

## ğŸ”„ Event Generation AyarlarÄ±

### 1. Cooldown Period

```python
EVENT_COOLDOWN_SECONDS = 5  # Minimum sÃ¼re iki event arasÄ±nda
```

**Neden?**
- AynÄ± kiÅŸi iÃ§in duplicate event'leri Ã¶nler
- False positive'leri azaltÄ±r

### 2. Frame Buffer

```python
EVENT_FRAME_BUFFER_SIZE = 10  # Collage iÃ§in frame sayÄ±sÄ±
EVENT_FRAME_INTERVAL = 2  # Her 2 frame'de bir kaydet
```

**SonuÃ§**: 10 frame buffer, 5 FPS â†’ 2 saniyelik event

---

## ğŸ“Š Performance Benchmarks (Referans)

### Hardware: NVIDIA T4 GPU

| Model | Resolution | FPS | Latency |
|-------|-----------|-----|---------|
| YOLOv8n | 640x640 | ~680 | 1.47ms |
| YOLOv8s | 640x640 | ~375 | 2.66ms |

### Hardware: Raspberry Pi 4 (CPU)

| Model | Resolution | FPS | Latency |
|-------|-----------|-----|---------|
| YOLOv8n | 640x640 | ~12 | 80ms |
| YOLOv8s | 640x640 | ~8 | 128ms |

**Ã–neri**: Raspberry Pi iÃ§in sadece YOLOv8n kullanÄ±n!

---

## ğŸ§ª Test Stratejisi

### Phase 1: Baseline Test (1 gÃ¼n)

1. **YOLOv8n ile baÅŸla**
   - Confidence: 0.25
   - Resolution: 640x640
   - FPS: 5

2. **Thermal enhancement test et**
   - CLAHE ile/without karÅŸÄ±laÅŸtÄ±r
   - mAP Ã¶lÃ§

3. **Latency Ã¶lÃ§**
   - RTSP â†’ Detection â†’ Event generation

### Phase 2: Optimization (2-3 gÃ¼n)

1. **Confidence threshold sweep**
   - 0.2, 0.25, 0.3, 0.4, 0.5
   - False positive/negative oranÄ±

2. **Model comparison**
   - YOLOv8n vs YOLOv8s
   - FPS vs Accuracy trade-off

3. **Stream optimization**
   - MJPEG vs WebRTC latency
   - Bandwidth kullanÄ±mÄ±

### Phase 3: Fine-tuning (1-2 gÃ¼n)

1. **Zone/ROI testing**
   - Polygon accuracy
   - Motion sensitivity

2. **Cooldown optimization**
   - Event frequency
   - Duplicate detection

3. **Multi-camera test**
   - Concurrent stream handling
   - Resource usage

---

## ğŸ“ Ã–nerilen Config Template

```json
{
  "detection": {
    "model": "yolov8n-person",
    "confidence_threshold": 0.25,
    "nms_iou_threshold": 0.45,
    "inference_resolution": [640, 640],
    "inference_fps": 5
  },
  "thermal": {
    "enable_enhancement": true,
    "enhancement_method": "clahe",
    "sensitivity": 8,
    "min_area": 450,
    "cooldown": 4
  },
  "stream": {
    "mode": "mjpeg",
    "protocol": "tcp",
    "buffer_size": 1,
    "downscale_resolution": [640, 480]
  },
  "event": {
    "cooldown_seconds": 5,
    "frame_buffer_size": 10,
    "frame_interval": 2
  }
}
```

---

## ğŸ”— Referanslar

1. **YOLOv8 Thermal**: Springer 2025 - "Person detection in thermal images using kurtosis based histogram enhancement and YOLOv8"
2. **YOLOv8n vs YOLOv8s**: Ultralytics Official Benchmarks 2024
3. **RTSP Optimization**: Roboflow Blog - "How to Run Computer Vision Models on RTSP Streams"
4. **Thermal Camera Best Practices**: FLIR - "The Importance of Thermal Sensitivity (NETD) for Detection Accuracy"
5. **WebRTC vs RTSP**: Wowza Media Systems 2024

---

## ğŸš€ Implementation Checklist

- [ ] YOLOv8n model indir ve test et
- [ ] Thermal enhancement pipeline implement et
- [ ] RTSP TCP connection test et
- [ ] Confidence threshold sweep yap
- [ ] Multi-camera concurrent test
- [ ] Event cooldown optimize et
- [ ] WebRTC integration (opsiyonel)

---

## ğŸ’¡ Pro Tips

1. **Her zaman TCP kullan**: UDP packet loss â†’ frame tearing
2. **Thermal iÃ§in enhancement zorunlu**: mAP %6-10 artÄ±ÅŸ
3. **Inference FPS â‰  Camera FPS**: 5 FPS inference yeterli
4. **TensorRT kullan**: NVIDIA GPU varsa 2-3x hÄ±zlanma
5. **Cooldown period kritik**: Duplicate event'leri Ã¶nler
6. **Zone testing**: GerÃ§ek senaryoda test et, simÃ¼lasyonda deÄŸil

---

**Son GÃ¼ncelleme**: 2026-01-20  
**Kaynak**: 2024-2025 production deployments ve research papers
